{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72974f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé¨ Starting Enhanced IMDb Scraper\n",
      "üéØ Genres: 9\n",
      "üìä Already processed: 730 movies\n",
      "üöÄ Starting parallel scraping...\n",
      "\n",
      "\u001b[91m[FAMILY] Starting link collection...\u001b[0m\n",
      "\u001b[92m[FANTASY] Starting link collection...\u001b[0m\n",
      "\u001b[93m[FILM-NOIR] Starting link collection...\u001b[0m\n",
      "\u001b[91m[FAMILY] 'Load More' clicked 1/8\u001b[0m\n",
      "\u001b[94m[GAME-SHOW] Starting link collection...\u001b[0m\n",
      "\u001b[92m[FANTASY] 'Load More' clicked 1/8\u001b[0m\n",
      "\u001b[93m[FILM-NOIR] 'Load More' clicked 1/8\u001b[0m\n",
      "\u001b[94m[GAME-SHOW] 'Load More' clicked 1/8\u001b[0m\n",
      "\u001b[96m[HORROR] Starting link collection...\u001b[0m\n",
      "\u001b[95m[HISTORY] Starting link collection...\u001b[0m\n",
      "\u001b[96m[HORROR] 'Load More' clicked 1/8\u001b[0m\n",
      "\u001b[95m[HISTORY] 'Load More' clicked 1/8\u001b[0m\n",
      "\u001b[91m[MUSICAL] Starting link collection...\u001b[0m\n",
      "\u001b[97m[MUSIC] Starting link collection...\u001b[0m\n",
      "\u001b[91m[MUSICAL] 'Load More' clicked 1/8\u001b[0m\n",
      "\u001b[97m[MUSIC] 'Load More' clicked 1/8\u001b[0m\n",
      "\u001b[91m[FAMILY] + 100 new | Total: 100\u001b[0m\n",
      "\u001b[92m[FANTASY] + 100 new | Total: 100\u001b[0m\n",
      "\u001b[94m[GAME-SHOW] + 100 new | Total: 100\u001b[0m\n",
      "\u001b[93m[FILM-NOIR] + 100 new | Total: 100\u001b[0m\n",
      "\u001b[91m[FAMILY] 'Load More' clicked 2/8\u001b[0m\n",
      "\u001b[94m[GAME-SHOW] 'Load More' clicked 2/8\u001b[0m\n",
      "\u001b[92m[FANTASY] 'Load More' clicked 2/8\u001b[0m\n",
      "\u001b[93m[FILM-NOIR] 'Load More' clicked 2/8\u001b[0m\n",
      "\u001b[96m[HORROR] + 100 new | Total: 100\u001b[0m\n",
      "\u001b[95m[HISTORY] + 100 new | Total: 100\u001b[0m\n",
      "\u001b[96m[HORROR] 'Load More' clicked 2/8\u001b[0m\n",
      "\u001b[91m[MUSICAL] + 100 new | Total: 100\u001b[0m\n",
      "\u001b[95m[HISTORY] 'Load More' clicked 2/8\u001b[0m\n",
      "\u001b[97m[MUSIC] + 100 new | Total: 100\u001b[0m\n",
      "\u001b[91m[MUSICAL] 'Load More' clicked 2/8\u001b[0m\n",
      "\u001b[97m[MUSIC] 'Load More' clicked 2/8\u001b[0m\n",
      "\u001b[92m[FANTASY] + 50 new | Total: 150\u001b[0m\n",
      "\u001b[94m[GAME-SHOW] + 50 new | Total: 150\u001b[0m\n",
      "\u001b[91m[FAMILY] + 50 new | Total: 150\u001b[0m\n",
      "\u001b[93m[FILM-NOIR] + 50 new | Total: 150\u001b[0m\n",
      "\u001b[96m[HORROR] + 50 new | Total: 150\u001b[0m\n",
      "\u001b[94m[GAME-SHOW] 'Load More' clicked 3/8\u001b[0m\n",
      "\u001b[92m[FANTASY] 'Load More' clicked 3/8\u001b[0m\n",
      "\u001b[91m[FAMILY] 'Load More' clicked 3/8\u001b[0m\n",
      "\u001b[96m[HORROR] 'Load More' clicked 3/8\u001b[0m\n",
      "\u001b[93m[FILM-NOIR] 'Load More' clicked 3/8\u001b[0m\n",
      "\u001b[95m[HISTORY] + 50 new | Total: 150\u001b[0m\n",
      "\u001b[91m[MUSICAL] + 50 new | Total: 150\u001b[0m\n",
      "\u001b[95m[HISTORY] 'Load More' clicked 3/8\u001b[0m\n",
      "\u001b[91m[MUSICAL] 'Load More' clicked 3/8\u001b[0m\n",
      "\u001b[97m[MUSIC] + 50 new | Total: 150\u001b[0m\n",
      "\u001b[97m[MUSIC] 'Load More' clicked 3/8\u001b[0m\n",
      "\u001b[94m[GAME-SHOW] + 50 new | Total: 200\u001b[0m\n",
      "\u001b[91m[FAMILY] + 50 new | Total: 200\u001b[0m\n",
      "\u001b[92m[FANTASY] + 50 new | Total: 200\u001b[0m\n",
      "\u001b[96m[HORROR] + 50 new | Total: 200\u001b[0m\n",
      "\u001b[94m[GAME-SHOW] 'Load More' clicked 4/8\u001b[0m\n",
      "\u001b[93m[FILM-NOIR] + 50 new | Total: 200\u001b[0m\n",
      "\u001b[91m[FAMILY] 'Load More' clicked 4/8\u001b[0m\n",
      "\u001b[92m[FANTASY] 'Load More' clicked 4/8\u001b[0m\n",
      "\u001b[96m[HORROR] 'Load More' clicked 4/8\u001b[0m\n",
      "\u001b[93m[FILM-NOIR] 'Load More' clicked 4/8\u001b[0m\n",
      "\u001b[95m[HISTORY] + 50 new | Total: 200\u001b[0m\n",
      "\u001b[91m[MUSICAL] + 50 new | Total: 200\u001b[0m\n",
      "\u001b[97m[MUSIC] + 50 new | Total: 200\u001b[0m\n",
      "\u001b[91m[MUSICAL] 'Load More' clicked 4/8\u001b[0m\n",
      "\u001b[95m[HISTORY] 'Load More' clicked 4/8\u001b[0m\n",
      "\u001b[97m[MUSIC] 'Load More' clicked 4/8\u001b[0m\n",
      "\u001b[94m[GAME-SHOW] + 50 new | Total: 250\u001b[0m\n",
      "\u001b[92m[FANTASY] + 50 new | Total: 250\u001b[0m\n",
      "\u001b[91m[FAMILY] + 50 new | Total: 250\u001b[0m\n",
      "\u001b[94m[GAME-SHOW] 'Load More' clicked 5/8\u001b[0m\n",
      "\u001b[93m[FILM-NOIR] + 50 new | Total: 250\u001b[0m\n",
      "\u001b[96m[HORROR] + 50 new | Total: 250\u001b[0m\n",
      "\u001b[92m[FANTASY] 'Load More' clicked 5/8\u001b[0m\n",
      "\u001b[91m[FAMILY] 'Load More' clicked 5/8\u001b[0m\n",
      "\u001b[93m[FILM-NOIR] 'Load More' clicked 5/8\u001b[0m\n",
      "\u001b[96m[HORROR] 'Load More' clicked 5/8\u001b[0m\n",
      "\u001b[91m[MUSICAL] + 50 new | Total: 250\u001b[0m\n",
      "\u001b[95m[HISTORY] + 50 new | Total: 250\u001b[0m\n",
      "\u001b[91m[MUSICAL] 'Load More' clicked 5/8\u001b[0m\n",
      "\u001b[95m[HISTORY] 'Load More' clicked 5/8\u001b[0m\n",
      "\u001b[97m[MUSIC] + 50 new | Total: 250\u001b[0m\n",
      "\u001b[97m[MUSIC] 'Load More' clicked 5/8\u001b[0m\n",
      "\u001b[94m[GAME-SHOW] + 50 new | Total: 300\u001b[0m\n",
      "\u001b[92m[FANTASY] + 50 new | Total: 300\u001b[0m\n",
      "\u001b[91m[FAMILY] + 50 new | Total: 300\u001b[0m\n",
      "\u001b[93m[FILM-NOIR] + 50 new | Total: 300\u001b[0m\n",
      "\u001b[96m[HORROR] + 50 new | Total: 300\u001b[0m\n",
      "\u001b[94m[GAME-SHOW] 'Load More' clicked 6/8\u001b[0m\n",
      "\u001b[92m[FANTASY] 'Load More' clicked 6/8\u001b[0m\n",
      "\u001b[91m[FAMILY] 'Load More' clicked 6/8\u001b[0m\n",
      "\u001b[93m[FILM-NOIR] 'Load More' clicked 6/8\u001b[0m\n",
      "\u001b[96m[HORROR] 'Load More' clicked 6/8\u001b[0m\n",
      "\u001b[91m[MUSICAL] + 50 new | Total: 300\u001b[0m\n",
      "\u001b[95m[HISTORY] + 50 new | Total: 300\u001b[0m\n",
      "\u001b[91m[MUSICAL] 'Load More' clicked 6/8\u001b[0m\n",
      "\u001b[95m[HISTORY] 'Load More' clicked 6/8\u001b[0m\n",
      "\u001b[97m[MUSIC] + 50 new | Total: 300\u001b[0m\n",
      "\u001b[94m[GAME-SHOW] + 50 new | Total: 350\u001b[0m\n",
      "\u001b[92m[FANTASY] + 50 new | Total: 350\u001b[0m\n",
      "\u001b[97m[MUSIC] 'Load More' clicked 6/8\u001b[0m\n",
      "\u001b[93m[FILM-NOIR] + 50 new | Total: 350\u001b[0m\u001b[91m[FAMILY] + 50 new | Total: 350\u001b[0m\n",
      "\n",
      "\u001b[94m[GAME-SHOW] 'Load More' clicked 7/8\u001b[0m\n",
      "\u001b[96m[HORROR] + 50 new | Total: 350\u001b[0m\n",
      "\u001b[92m[FANTASY] 'Load More' clicked 7/8\u001b[0m\n",
      "\u001b[93m[FILM-NOIR] 'Load More' clicked 7/8\u001b[0m\n",
      "\u001b[91m[FAMILY] 'Load More' clicked 7/8\u001b[0m\n",
      "\u001b[96m[HORROR] 'Load More' clicked 7/8\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from threading import Thread, Lock\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =====================================================================================================\n",
    "\n",
    "lock = Lock()\n",
    "save_counter = 0\n",
    "total_scraped = 0\n",
    "\n",
    "# =====================================================================================================\n",
    "\n",
    "# R…ôngl…ôr (ANSI escape kodlarƒ±)\n",
    "colors = [\"\\033[91m\", \"\\033[92m\", \"\\033[93m\", \"\\033[94m\", \"\\033[95m\", \"\\033[96m\", \"\\033[97m\"]\n",
    "RESET = \"\\033[0m\"\n",
    "\n",
    "# =====================================================================================================\n",
    "\n",
    "def save_data(new_data, filename=\"imdb_review.json\"):\n",
    "    global save_counter, total_scraped\n",
    "    with lock:\n",
    "        if os.path.exists(filename):\n",
    "            with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "                try:\n",
    "                    old_data = json.load(f)\n",
    "                except:\n",
    "                    old_data = []\n",
    "        else:\n",
    "            old_data = []\n",
    "\n",
    "        all_data = old_data + new_data\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(all_data, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        save_counter += 1\n",
    "        total_scraped = len(all_data)\n",
    "        print(f\"\\nüìÅ SAVE #{save_counter}: Added {len(new_data)} movies | Total: {len(all_data)} movies\\n\")\n",
    "\n",
    "# =====================================================================================================\n",
    "\n",
    "def load_existing_links(filename=\"imdb_review.json\"):\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                return {d[\"URL\"] for d in data if \"URL\" in d}\n",
    "            except:\n",
    "                return set()\n",
    "    return set()\n",
    "\n",
    "# =====================================================================================================\n",
    "\n",
    "def get_driver():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--disable-extensions\")\n",
    "    options.add_argument(\"--disable-logging\")\n",
    "    options.add_argument(\"--disable-web-security\")\n",
    "    options.add_argument(\"--allow-running-insecure-content\")\n",
    "    prefs = {\n",
    "        \"profile.managed_default_content_settings.images\": 2,\n",
    "        \"profile.default_content_setting_values.notifications\": 2\n",
    "    }\n",
    "    options.add_experimental_option(\"prefs\", prefs)\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    options.add_experimental_option('useAutomationExtension', False)\n",
    "\n",
    "    driver = webdriver.Chrome(\n",
    "        service=Service(executable_path=ChromeDriverManager().install()),\n",
    "        options=options\n",
    "    )\n",
    "    \n",
    "    # Anti-detection\n",
    "    driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "    \n",
    "    return driver\n",
    "\n",
    "# =====================================================================================================\n",
    "\n",
    "def scroll_js(driver, pixels=3000):\n",
    "    driver.execute_script(f\"window.scrollBy(0, {pixels});\")\n",
    "\n",
    "# =====================================================================================================\n",
    "\n",
    "def click_element_safely(driver, element):\n",
    "    try:\n",
    "        driver.execute_script(\"arguments[0].click();\", element)\n",
    "        return True\n",
    "    except:\n",
    "        try:\n",
    "            element.click()\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "# =====================================================================================================\n",
    "\n",
    "def close_rate_popup(driver):\n",
    "    try:\n",
    "        popups = [\n",
    "            \"button[data-testid='rate-dismiss']\",\n",
    "            \"button[aria-label='Close']\",\n",
    "            \".ipc-promptable-base__close-button\",\n",
    "            \".ipc-modal__close-button\"\n",
    "        ]\n",
    "        for popup_selector in popups:\n",
    "            try:\n",
    "                popup_close = driver.find_element(By.CSS_SELECTOR, popup_selector)\n",
    "                if popup_close.is_displayed():\n",
    "                    click_element_safely(driver, popup_close)\n",
    "                    time.sleep(0.5)\n",
    "                    break\n",
    "            except:\n",
    "                continue\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# =====================================================================================================\n",
    "\n",
    "def get_all_movie_links(driver, category_url, color):\n",
    "    \"\"\"Kategoriyadakƒ± b√ºt√ºn film linkl…ôrini topla\"\"\"\n",
    "    try:\n",
    "        driver.get(category_url)\n",
    "        time.sleep(random.uniform(3, 5))\n",
    "        close_rate_popup(driver)\n",
    "    except Exception as e:\n",
    "        print(f\"{color}[ERROR] Failed to load {category_url}: {e}{RESET}\")\n",
    "        return set()\n",
    "\n",
    "    all_links = set()\n",
    "    scroll_count = 0\n",
    "    see_more_count = 0\n",
    "    max_scrolls = 150  \n",
    "    no_new_products_count = 0\n",
    "    manual_see_more_clicks = 10  \n",
    "\n",
    "    print(f\"{color}[{category_url.split('=')[-1].upper()}] Starting link collection...{RESET}\")\n",
    "\n",
    "    while scroll_count < max_scrolls:\n",
    "        # S…ôhif…ôni scroll et\n",
    "        scroll_js(driver, 4000)\n",
    "        time.sleep(random.uniform(2, 4))\n",
    "        close_rate_popup(driver)\n",
    "\n",
    "        # \"Load More\" d√ºym…ôsini tap v…ô bas\n",
    "        if see_more_count < manual_see_more_clicks:\n",
    "            try:\n",
    "                load_more_selectors = [\n",
    "                    \"div.sc-5fb85acc-0 span button\",\n",
    "                    \".ipc-see-more__button\",\n",
    "                    \"button.ipc-see-more__button\",\n",
    "                    \".ipc-see-more button\"\n",
    "                ]\n",
    "                \n",
    "                for selector in load_more_selectors:\n",
    "                    try:\n",
    "                        load_more = WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.CSS_SELECTOR, selector)))\n",
    "                        if load_more.is_displayed():\n",
    "                            if click_element_safely(driver, load_more):\n",
    "                                see_more_count += 1\n",
    "                                print(f\"{color}[{category_url.split('=')[-1].upper()}] 'Load More' clicked {see_more_count}/{manual_see_more_clicks}{RESET}\")\n",
    "                                time.sleep(random.uniform(3, 5))\n",
    "                                break\n",
    "                    except:\n",
    "                        continue\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # Film linkl…ôrini topla\n",
    "        link_selectors = [\n",
    "            \".dli-title.with-margin a\",\n",
    "            \".ipc-title-link-wrapper\",\n",
    "            \"a.ipc-title-link-wrapper\",\n",
    "            \".cli-title a\",\n",
    "            \"h3.ipc-title a\"\n",
    "        ]\n",
    "        \n",
    "        current_links = set()\n",
    "        for selector in link_selectors:\n",
    "            try:\n",
    "                elements = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "                for e in elements:\n",
    "                    href = e.get_attribute(\"href\")\n",
    "                    if href and \"/title/tt\" in href and \"?\" in href:\n",
    "                        # URL-ni t…ômizl…ô\n",
    "                        clean_href = href.split(\"?\")[0]\n",
    "                        current_links.add(clean_href)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        new_products = current_links - all_links\n",
    "\n",
    "        if new_products:\n",
    "            all_links.update(new_products)\n",
    "            no_new_products_count = 0\n",
    "            print(f\"{color}[{category_url.split('=')[-1].upper()}] + {len(new_products)} new | Total: {len(all_links)}{RESET}\")\n",
    "        else:\n",
    "            no_new_products_count += 1\n",
    "\n",
    "        # ∆èg…ôr 10 d…ôf…ô yeni link tapƒ±lmasa v…ô kifay…ôt q…ôd…ôr link toplandƒ±sa, dayanƒ±rƒ±q\n",
    "        if no_new_products_count >= 10 and len(all_links) > 200:\n",
    "            print(f\"{color}[{category_url.split('=')[-1].upper()}] No new links for 10 iterations. Stopping...{RESET}\")\n",
    "            break\n",
    "\n",
    "        scroll_count += 1\n",
    "\n",
    "    print(f\"{color}[{category_url.split('=')[-1].upper()}] ‚úÖ Total links collected: {len(all_links)}{RESET}\")\n",
    "    return all_links\n",
    "\n",
    "# =====================================================================================================\n",
    "\n",
    "def scrape_movie_reviews(driver, movie_url, color, genre):\n",
    "    \"\"\"Bir filmin b√ºt√ºn r…ôyl…ôrini topla\"\"\"\n",
    "    try:\n",
    "        driver.set_page_load_timeout(45)\n",
    "        driver.get(movie_url)\n",
    "        time.sleep(random.uniform(2, 4))\n",
    "        close_rate_popup(driver)\n",
    "    except TimeoutException:\n",
    "        print(f\"{color}[{genre}] ‚è±Ô∏è  TIMEOUT: {movie_url[-15:]}{RESET}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"{color}[{genre}] ‚ùå ERROR: {movie_url[-15:]} - {e}{RESET}\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    data = {\"URL\": movie_url, \"Genre\": genre}\n",
    "\n",
    "    # Film adƒ±\n",
    "    name_selectors = [\n",
    "        \"span.hero__primary-text\",\n",
    "        \"h1[data-testid='hero-title-block__title']\",\n",
    "        \".sc-b73cd867-0 h1\",\n",
    "        \"h1.sc-b73cd867-0\"\n",
    "    ]\n",
    "    \n",
    "    for selector in name_selectors:\n",
    "        name = soup.select_one(selector)\n",
    "        if name:\n",
    "            data[\"Name\"] = name.get_text(strip=True)\n",
    "            break\n",
    "    else:\n",
    "        data[\"Name\"] = \"Unknown\"\n",
    "\n",
    "    # Reytinq\n",
    "    rating_selectors = [\n",
    "        \"span.ipc-rating-star--rating\",\n",
    "        \".sc-7ab21ed2-1 span\",\n",
    "        \"[data-testid='hero-rating-bar__aggregate-rating__score'] span\"\n",
    "    ]\n",
    "    \n",
    "    for selector in rating_selectors:\n",
    "        star_rate = soup.select_one(selector)\n",
    "        if star_rate:\n",
    "            try:\n",
    "                rating_text = star_rate.get_text(strip=True)\n",
    "                data[\"Star_Rating\"] = float(rating_text)\n",
    "            except:\n",
    "                data[\"Star_Rating\"] = None\n",
    "            break\n",
    "    else:\n",
    "        data[\"Star_Rating\"] = None\n",
    "\n",
    "    # T…ôsvir\n",
    "    description_selectors = [\n",
    "        \"span.sc-bf30a0e-2.bRimta\",\n",
    "        \"[data-testid='plot-xs_to_m'] span\",\n",
    "        \".ipc-html-content-inner-div\",\n",
    "        \"[data-testid='plot'] span\"\n",
    "    ]\n",
    "    \n",
    "    for selector in description_selectors:\n",
    "        description = soup.select_one(selector)\n",
    "        if description:\n",
    "            data[\"Description\"] = description.get_text(strip=True)\n",
    "            break\n",
    "    else:\n",
    "        data[\"Description\"] = None\n",
    "\n",
    "    # User Reviews s…ôhif…ôsin…ô get\n",
    "    reviews_list = []\n",
    "    try:\n",
    "        # User reviews linkini tap\n",
    "        user_reviews_selectors = [\n",
    "            \"a[href*='reviews']\",\n",
    "            \"a[data-testid='reviews-header']\"\n",
    "        ]\n",
    "        \n",
    "        user_reviews_button = None\n",
    "        for selector in user_reviews_selectors:\n",
    "            try:\n",
    "                user_reviews_button = WebDriverWait(driver, 8).until(EC.element_to_be_clickable((By.CSS_SELECTOR, selector)))\n",
    "                if user_reviews_button.is_displayed():\n",
    "                    break\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        # XPath il…ô d…ô c…ôhd et\n",
    "        if not user_reviews_button:\n",
    "            try:\n",
    "                user_reviews_button = WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.XPATH, \"//a[contains(text(), 'User reviews') or contains(text(), 'reviews')]\")))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        if user_reviews_button:\n",
    "            click_element_safely(driver, user_reviews_button)\n",
    "            time.sleep(random.uniform(3, 5))\n",
    "            close_rate_popup(driver)\n",
    "\n",
    "            # B√ºt√ºn r…ôyl…ôri y√ºkl…ôm…ôk √º√ß√ºn scroll et\n",
    "            last_review_count = 0\n",
    "            no_new_reviews_count = 0\n",
    "            max_load_attempts = 15  # Artƒ±rƒ±ldƒ±\n",
    "            \n",
    "            while no_new_reviews_count < max_load_attempts:\n",
    "                # S…ôhif…ôni a≈üaƒüƒ± scroll et\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(random.uniform(2, 4))\n",
    "                close_rate_popup(driver)\n",
    "                \n",
    "                # \"Load More\" d√ºym…ôsini tap\n",
    "                try:\n",
    "                    load_more_selectors = [\n",
    "                        \".ipc-see-more__button\",\n",
    "                        \"button.ipc-see-more__button\",\n",
    "                        \".sc-e2b012eb-0 button\",\n",
    "                        \"button[data-testid='load-more-trigger']\"\n",
    "                    ]\n",
    "                    \n",
    "                    load_more_found = False\n",
    "                    for selector in load_more_selectors:\n",
    "                        try:\n",
    "                            load_more = driver.find_element(By.CSS_SELECTOR, selector)\n",
    "                            if load_more.is_displayed() and load_more.is_enabled():\n",
    "                                if click_element_safely(driver, load_more):\n",
    "                                    load_more_found = True\n",
    "                                    time.sleep(random.uniform(3, 5))\n",
    "                                    break\n",
    "                        except:\n",
    "                            continue\n",
    "                    \n",
    "                    if not load_more_found:\n",
    "                        no_new_reviews_count += 1\n",
    "                        \n",
    "                except:\n",
    "                    no_new_reviews_count += 1\n",
    "                \n",
    "                # Hazƒ±rda s…ôhif…ôd…ôki r…ôy sayƒ±nƒ± yoxla\n",
    "                current_reviews = driver.find_elements(By.CSS_SELECTOR, \".ipc-html-content-inner-div\")\n",
    "                current_count = len(current_reviews)\n",
    "                \n",
    "                if current_count > last_review_count:\n",
    "                    last_review_count = current_count\n",
    "                    no_new_reviews_count = 0\n",
    "                    if current_count % 50 == 0:  # H…ôr 50 r…ôyd…ôn bir g√∂ster\n",
    "                        print(f\"{color}[{genre}] üìù {current_count} reviews loaded for {data['Name'][:30]}{RESET}\")\n",
    "                else:\n",
    "                    no_new_reviews_count += 1\n",
    "\n",
    "            # R…ôyl…ôri topla\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            \n",
    "            # R…ôy m…ôtnl…ôri\n",
    "            reviews = soup.select(\".ipc-html-content-inner-div\")\n",
    "            \n",
    "            # Reytinql…ôr\n",
    "            ratings = soup.select(\"span.ipc-rating-star--rating\")\n",
    "            \n",
    "            print(f\"{color}[{genre}] ‚úÖ {len(reviews)} reviews scraped for '{data['Name'][:40]}'{RESET}\")\n",
    "            \n",
    "            # R…ôyl…ôri birl…ô≈üdir\n",
    "            for i, review in enumerate(reviews):\n",
    "                review_text = review.get_text(strip=True)\n",
    "                \n",
    "                # Reytinqi tap\n",
    "                rating = None\n",
    "                if i < len(ratings):\n",
    "                    try:\n",
    "                        rating_text = ratings[i].get_text(strip=True)\n",
    "                        rating = float(rating_text)\n",
    "                    except (ValueError, AttributeError):\n",
    "                        rating = None\n",
    "                \n",
    "                if review_text and len(review_text) > 10:  # √áox qƒ±sa r…ôyl…ôri …ôlav…ô etm…ô\n",
    "                    reviews_list.append({\n",
    "                        \"Review\": review_text,\n",
    "                        \"Rating\": rating\n",
    "                    })\n",
    "        else:\n",
    "            print(f\"{color}[{genre}] ‚ö†Ô∏è  No reviews button found for {data['Name'][:30]}{RESET}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{color}[{genre}] ‚ùå Reviews scraping failed for {data['Name'][:30]}: {e}{RESET}\")\n",
    "\n",
    "    data[\"Reviews\"] = reviews_list\n",
    "    data[\"Review_Count\"] = len(reviews_list)\n",
    "    return data\n",
    "\n",
    "# =====================================================================================================\n",
    "\n",
    "def scrap_category(category_url, processed_links, list_data, position, color):\n",
    "    \"\"\"Bir kategoriyanƒ±n b√ºt√ºn filml…ôrini scrap et\"\"\"\n",
    "    genre = category_url.split('=')[-1].upper()\n",
    "    driver = get_driver()\n",
    "    \n",
    "    try:\n",
    "        # ∆èvv…ôlc…ô b√ºt√ºn film linkl…ôrini topla\n",
    "        all_links = get_all_movie_links(driver, category_url, color)\n",
    "        \n",
    "        if not all_links:\n",
    "            print(f\"{color}[{genre}] ‚ùå No links found{RESET}\")\n",
    "            return\n",
    "        \n",
    "        # ∆èvv…ôld…ôn emal edilmi≈ü linkl…ôri √ßƒ±xar\n",
    "        with lock:\n",
    "            new_links = list(all_links - processed_links)\n",
    "            processed_links.update(new_links)\n",
    "        \n",
    "        print(f\"{color}[{genre}] üéØ Processing {len(new_links)} new movies{RESET}\")\n",
    "        \n",
    "        if not new_links:\n",
    "            print(f\"{color}[{genre}] ‚ÑπÔ∏è  No new movies to process{RESET}\")\n",
    "            return\n",
    "        \n",
    "        # H…ôr bir filmi emal et\n",
    "        processed_count = 0\n",
    "        batch_data = []\n",
    "        \n",
    "        for i, link in enumerate(new_links, 1):\n",
    "            try:\n",
    "                movie_data = scrape_movie_reviews(driver, link, color, genre)\n",
    "                \n",
    "                if movie_data and movie_data.get(\"Reviews\"):\n",
    "                    batch_data.append(movie_data)\n",
    "                    processed_count += 1\n",
    "                    \n",
    "                    print(f\"{color}[{genre}] üìä Progress: {i}/{len(new_links)} | Successful: {processed_count} | Reviews: {movie_data.get('Review_Count', 0)}{RESET}\")\n",
    "                    \n",
    "                    # H…ôr 5 filmd…ôn sonra save et\n",
    "                    if len(batch_data) >= 5:\n",
    "                        save_data(batch_data.copy())\n",
    "                        batch_data.clear()\n",
    "                else:\n",
    "                    print(f\"{color}[{genre}] ‚ö†Ô∏è  Skipped: {link[-20:]} (No reviews){RESET}\")\n",
    "                \n",
    "                # Random delay\n",
    "                time.sleep(random.uniform(1, 3))\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"{color}[{genre}] ‚ùå Error processing {link[-20:]}: {e}{RESET}\")\n",
    "                continue\n",
    "        \n",
    "        # Qalan m…ôlumatlarƒ± save et\n",
    "        if batch_data:\n",
    "            save_data(batch_data)\n",
    "        \n",
    "        print(f\"{color}[{genre}] üéâ COMPLETED: {processed_count}/{len(new_links)} movies successfully scraped{RESET}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"{color}[{genre}] ‚ùå Category scraping failed: {e}{RESET}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "# =====================================================================================================\n",
    "\n",
    "# URL-l…ôr (b√ºt√ºn janrlar)\n",
    "urls = [\n",
    "    # \"https://www.imdb.com/search/title/?genres=action\",\n",
    "    # \"https://www.imdb.com/search/title/?genres=adventure\",\n",
    "    # \"https://www.imdb.com/search/title/?genres=animation\",\n",
    "    # \"https://www.imdb.com/search/title/?genres=biography\",\n",
    "    # \"https://www.imdb.com/search/title/?genres=comedy\",\n",
    "    # \"https://www.imdb.com/search/title/?genres=crime\",\n",
    "    # \"https://www.imdb.com/search/title/?genres=documentary\",\n",
    "    # \"https://www.imdb.com/search/title/?genres=drama\",\n",
    "    \"https://www.imdb.com/search/title/?genres=family\",\n",
    "    \"https://www.imdb.com/search/title/?genres=fantasy\",\n",
    "    \"https://www.imdb.com/search/title/?genres=film-noir\",\n",
    "    \"https://www.imdb.com/search/title/?genres=game-show\",\n",
    "    \"https://www.imdb.com/search/title/?genres=history\",\n",
    "    \"https://www.imdb.com/search/title/?genres=horror\",\n",
    "    \"https://www.imdb.com/search/title/?genres=music\",\n",
    "    \"https://www.imdb.com/search/title/?genres=musical\",\n",
    "    \"https://www.imdb.com/search/title/?genres=mystery\",\n",
    "    # \"https://www.imdb.com/search/title/?genres=news\",\n",
    "    # \"https://www.imdb.com/search/title/?genres=reality-tv\",\n",
    "    # \"https://www.imdb.com/search/title/?genres=romance\",\n",
    "    # \"https://www.imdb.com/search/title/?genres=sci-fi\",\n",
    "    # \"https://www.imdb.com/search/title/?genres=short\",\n",
    "    # \"https://www.imdb.com/search/title/?genres=sport\",\n",
    "    # \"https://www.imdb.com/search/title/?genres=talk-show\",\n",
    "    # \"https://www.imdb.com/search/title/?genres=thriller\",\n",
    "    # \"https://www.imdb.com/search/title/?genres=war\",\n",
    "    # \"https://www.imdb.com/search/title/?genres=western\"\n",
    "]\n",
    "\n",
    "# =====================================================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    processed_links = load_existing_links()\n",
    "    list_data = []\n",
    "    \n",
    "    print(f\"üé¨ Starting Enhanced IMDb Scraper\")\n",
    "    print(f\"üéØ Genres: {len(urls)}\")\n",
    "    print(f\"üìä Already processed: {len(processed_links)} movies\")\n",
    "    print(f\"üöÄ Starting parallel scraping...\\n\")\n",
    "    \n",
    "    threads = []\n",
    "    \n",
    "    # H…ôr bir URL √º√ß√ºn thread yarat\n",
    "    for idx, url in enumerate(urls):\n",
    "        color = colors[idx % len(colors)]\n",
    "        t = Thread(target=scrap_category, args=(url, processed_links, list_data, idx, color))\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "        time.sleep(1)  # Thread-l…ôr arasƒ± delay\n",
    "    \n",
    "    # B√ºt√ºn thread-l…ôri g√∂zl…ô\n",
    "    for i, t in enumerate(threads):\n",
    "        t.join()\n",
    "        print(f\"‚úÖ Thread {i+1} completed\")\n",
    "    \n",
    "    # Final save\n",
    "    if list_data:\n",
    "        save_data(list_data)\n",
    "    \n",
    "    print(f\"\\nüéâ ALL GENRES COMPLETED!\")\n",
    "    print(f\"üìÅ Data saved to: imdb_review.json\")\n",
    "    print(f\"üìä Total movies scraped: {total_scraped}\")\n",
    "    print(f\"üíæ Total saves performed: {save_counter}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
